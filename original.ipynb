{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/32/01d39x_s1sn9ywcywln8d29r0000gn/T/ipykernel_28275/2459606017.py:1: DtypeWarning: Columns (3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original = pd.read_csv('archive-3.zip', compression='zip')\n"
     ]
    }
   ],
   "source": [
    "original = pd.read_csv('archive-3.zip', compression='zip')\n",
    "df=original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'spkid', 'full_name', 'pdes', 'name', 'prefix', 'neo', 'pha', 'H',\n",
       "       'diameter', 'albedo', 'diameter_sigma', 'orbit_id', 'epoch',\n",
       "       'epoch_mjd', 'epoch_cal', 'equinox', 'e', 'a', 'q', 'i', 'om', 'w',\n",
       "       'ma', 'ad', 'n', 'tp', 'tp_cal', 'per', 'per_y', 'moid', 'moid_ld',\n",
       "       'sigma_e', 'sigma_a', 'sigma_q', 'sigma_i', 'sigma_om', 'sigma_w',\n",
       "       'sigma_ma', 'sigma_ad', 'sigma_n', 'sigma_tp', 'sigma_per', 'class',\n",
       "       'rms'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>spkid</th>\n",
       "      <th>full_name</th>\n",
       "      <th>pdes</th>\n",
       "      <th>name</th>\n",
       "      <th>prefix</th>\n",
       "      <th>neo</th>\n",
       "      <th>pha</th>\n",
       "      <th>H</th>\n",
       "      <th>diameter</th>\n",
       "      <th>albedo</th>\n",
       "      <th>diameter_sigma</th>\n",
       "      <th>orbit_id</th>\n",
       "      <th>epoch</th>\n",
       "      <th>epoch_mjd</th>\n",
       "      <th>epoch_cal</th>\n",
       "      <th>equinox</th>\n",
       "      <th>e</th>\n",
       "      <th>a</th>\n",
       "      <th>q</th>\n",
       "      <th>i</th>\n",
       "      <th>om</th>\n",
       "      <th>w</th>\n",
       "      <th>ma</th>\n",
       "      <th>ad</th>\n",
       "      <th>n</th>\n",
       "      <th>tp</th>\n",
       "      <th>tp_cal</th>\n",
       "      <th>per</th>\n",
       "      <th>per_y</th>\n",
       "      <th>moid</th>\n",
       "      <th>moid_ld</th>\n",
       "      <th>sigma_e</th>\n",
       "      <th>sigma_a</th>\n",
       "      <th>sigma_q</th>\n",
       "      <th>sigma_i</th>\n",
       "      <th>sigma_om</th>\n",
       "      <th>sigma_w</th>\n",
       "      <th>sigma_ma</th>\n",
       "      <th>sigma_ad</th>\n",
       "      <th>sigma_n</th>\n",
       "      <th>sigma_tp</th>\n",
       "      <th>sigma_per</th>\n",
       "      <th>class</th>\n",
       "      <th>rms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a0000001</td>\n",
       "      <td>2000001</td>\n",
       "      <td>1 Ceres</td>\n",
       "      <td>1</td>\n",
       "      <td>Ceres</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3.40</td>\n",
       "      <td>939.400</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.200</td>\n",
       "      <td>JPL 47</td>\n",
       "      <td>2458600.5</td>\n",
       "      <td>58600</td>\n",
       "      <td>20190427.0</td>\n",
       "      <td>J2000</td>\n",
       "      <td>0.076009</td>\n",
       "      <td>2.769165</td>\n",
       "      <td>2.558684</td>\n",
       "      <td>10.594067</td>\n",
       "      <td>80.305531</td>\n",
       "      <td>73.597695</td>\n",
       "      <td>77.372098</td>\n",
       "      <td>2.979647</td>\n",
       "      <td>0.213885</td>\n",
       "      <td>2.458239e+06</td>\n",
       "      <td>2.018043e+07</td>\n",
       "      <td>1683.145703</td>\n",
       "      <td>4.608202</td>\n",
       "      <td>1.59478</td>\n",
       "      <td>620.640533</td>\n",
       "      <td>4.819000e-12</td>\n",
       "      <td>1.032800e-11</td>\n",
       "      <td>1.956900e-11</td>\n",
       "      <td>4.608900e-09</td>\n",
       "      <td>6.168800e-08</td>\n",
       "      <td>6.624800e-08</td>\n",
       "      <td>7.820700e-09</td>\n",
       "      <td>1.111300e-11</td>\n",
       "      <td>1.196500e-12</td>\n",
       "      <td>3.782900e-08</td>\n",
       "      <td>9.415900e-09</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.43301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a0000002</td>\n",
       "      <td>2000002</td>\n",
       "      <td>2 Pallas</td>\n",
       "      <td>2</td>\n",
       "      <td>Pallas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>4.20</td>\n",
       "      <td>545.000</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>18.000</td>\n",
       "      <td>JPL 37</td>\n",
       "      <td>2459000.5</td>\n",
       "      <td>59000</td>\n",
       "      <td>20200531.0</td>\n",
       "      <td>J2000</td>\n",
       "      <td>0.229972</td>\n",
       "      <td>2.773841</td>\n",
       "      <td>2.135935</td>\n",
       "      <td>34.832932</td>\n",
       "      <td>173.024741</td>\n",
       "      <td>310.202392</td>\n",
       "      <td>144.975675</td>\n",
       "      <td>3.411748</td>\n",
       "      <td>0.213345</td>\n",
       "      <td>2.458321e+06</td>\n",
       "      <td>2.018072e+07</td>\n",
       "      <td>1687.410992</td>\n",
       "      <td>4.619880</td>\n",
       "      <td>1.23429</td>\n",
       "      <td>480.348639</td>\n",
       "      <td>3.193400e-08</td>\n",
       "      <td>4.033700e-09</td>\n",
       "      <td>8.832200e-08</td>\n",
       "      <td>3.469400e-06</td>\n",
       "      <td>6.272400e-06</td>\n",
       "      <td>9.128200e-06</td>\n",
       "      <td>8.859100e-06</td>\n",
       "      <td>4.961300e-09</td>\n",
       "      <td>4.653600e-10</td>\n",
       "      <td>4.078700e-05</td>\n",
       "      <td>3.680700e-06</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.35936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a0000003</td>\n",
       "      <td>2000003</td>\n",
       "      <td>3 Juno</td>\n",
       "      <td>3</td>\n",
       "      <td>Juno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>5.33</td>\n",
       "      <td>246.596</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>10.594</td>\n",
       "      <td>JPL 112</td>\n",
       "      <td>2459000.5</td>\n",
       "      <td>59000</td>\n",
       "      <td>20200531.0</td>\n",
       "      <td>J2000</td>\n",
       "      <td>0.256936</td>\n",
       "      <td>2.668285</td>\n",
       "      <td>1.982706</td>\n",
       "      <td>12.991043</td>\n",
       "      <td>169.851482</td>\n",
       "      <td>248.066193</td>\n",
       "      <td>125.435355</td>\n",
       "      <td>3.353865</td>\n",
       "      <td>0.226129</td>\n",
       "      <td>2.458446e+06</td>\n",
       "      <td>2.018112e+07</td>\n",
       "      <td>1592.013769</td>\n",
       "      <td>4.358696</td>\n",
       "      <td>1.03429</td>\n",
       "      <td>402.514639</td>\n",
       "      <td>3.052000e-08</td>\n",
       "      <td>3.471800e-09</td>\n",
       "      <td>8.139200e-08</td>\n",
       "      <td>3.223100e-06</td>\n",
       "      <td>1.664600e-05</td>\n",
       "      <td>1.772100e-05</td>\n",
       "      <td>8.110400e-06</td>\n",
       "      <td>4.363900e-09</td>\n",
       "      <td>4.413400e-10</td>\n",
       "      <td>3.528800e-05</td>\n",
       "      <td>3.107200e-06</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.33848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a0000004</td>\n",
       "      <td>2000004</td>\n",
       "      <td>4 Vesta</td>\n",
       "      <td>4</td>\n",
       "      <td>Vesta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3.00</td>\n",
       "      <td>525.400</td>\n",
       "      <td>0.4228</td>\n",
       "      <td>0.200</td>\n",
       "      <td>JPL 35</td>\n",
       "      <td>2458600.5</td>\n",
       "      <td>58600</td>\n",
       "      <td>20190427.0</td>\n",
       "      <td>J2000</td>\n",
       "      <td>0.088721</td>\n",
       "      <td>2.361418</td>\n",
       "      <td>2.151909</td>\n",
       "      <td>7.141771</td>\n",
       "      <td>103.810804</td>\n",
       "      <td>150.728541</td>\n",
       "      <td>95.861938</td>\n",
       "      <td>2.570926</td>\n",
       "      <td>0.271609</td>\n",
       "      <td>2.458248e+06</td>\n",
       "      <td>2.018051e+07</td>\n",
       "      <td>1325.432763</td>\n",
       "      <td>3.628837</td>\n",
       "      <td>1.13948</td>\n",
       "      <td>443.451432</td>\n",
       "      <td>2.332100e-10</td>\n",
       "      <td>1.514300e-09</td>\n",
       "      <td>1.928600e-09</td>\n",
       "      <td>2.170600e-07</td>\n",
       "      <td>3.880800e-07</td>\n",
       "      <td>1.789300e-07</td>\n",
       "      <td>1.206800e-06</td>\n",
       "      <td>1.648600e-09</td>\n",
       "      <td>2.612500e-10</td>\n",
       "      <td>4.103700e-06</td>\n",
       "      <td>1.274900e-06</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.39980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a0000005</td>\n",
       "      <td>2000005</td>\n",
       "      <td>5 Astraea</td>\n",
       "      <td>5</td>\n",
       "      <td>Astraea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>6.90</td>\n",
       "      <td>106.699</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>3.140</td>\n",
       "      <td>JPL 114</td>\n",
       "      <td>2459000.5</td>\n",
       "      <td>59000</td>\n",
       "      <td>20200531.0</td>\n",
       "      <td>J2000</td>\n",
       "      <td>0.190913</td>\n",
       "      <td>2.574037</td>\n",
       "      <td>2.082619</td>\n",
       "      <td>5.367427</td>\n",
       "      <td>141.571026</td>\n",
       "      <td>358.648418</td>\n",
       "      <td>17.846343</td>\n",
       "      <td>3.065455</td>\n",
       "      <td>0.238661</td>\n",
       "      <td>2.458926e+06</td>\n",
       "      <td>2.020032e+07</td>\n",
       "      <td>1508.414421</td>\n",
       "      <td>4.129814</td>\n",
       "      <td>1.09575</td>\n",
       "      <td>426.433027</td>\n",
       "      <td>2.373700e-08</td>\n",
       "      <td>3.970900e-09</td>\n",
       "      <td>6.092400e-08</td>\n",
       "      <td>2.740800e-06</td>\n",
       "      <td>2.894900e-05</td>\n",
       "      <td>2.984200e-05</td>\n",
       "      <td>8.303800e-06</td>\n",
       "      <td>4.729000e-09</td>\n",
       "      <td>5.522700e-10</td>\n",
       "      <td>3.474300e-05</td>\n",
       "      <td>3.490500e-06</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.52191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id    spkid       full_name pdes     name prefix neo pha     H  \\\n",
       "0  a0000001  2000001         1 Ceres    1    Ceres    NaN   N   N  3.40   \n",
       "1  a0000002  2000002        2 Pallas    2   Pallas    NaN   N   N  4.20   \n",
       "2  a0000003  2000003          3 Juno    3     Juno    NaN   N   N  5.33   \n",
       "3  a0000004  2000004         4 Vesta    4    Vesta    NaN   N   N  3.00   \n",
       "4  a0000005  2000005       5 Astraea    5  Astraea    NaN   N   N  6.90   \n",
       "\n",
       "   diameter  albedo  diameter_sigma orbit_id      epoch  epoch_mjd  \\\n",
       "0   939.400  0.0900           0.200   JPL 47  2458600.5      58600   \n",
       "1   545.000  0.1010          18.000   JPL 37  2459000.5      59000   \n",
       "2   246.596  0.2140          10.594  JPL 112  2459000.5      59000   \n",
       "3   525.400  0.4228           0.200   JPL 35  2458600.5      58600   \n",
       "4   106.699  0.2740           3.140  JPL 114  2459000.5      59000   \n",
       "\n",
       "    epoch_cal equinox         e         a         q          i          om  \\\n",
       "0  20190427.0   J2000  0.076009  2.769165  2.558684  10.594067   80.305531   \n",
       "1  20200531.0   J2000  0.229972  2.773841  2.135935  34.832932  173.024741   \n",
       "2  20200531.0   J2000  0.256936  2.668285  1.982706  12.991043  169.851482   \n",
       "3  20190427.0   J2000  0.088721  2.361418  2.151909   7.141771  103.810804   \n",
       "4  20200531.0   J2000  0.190913  2.574037  2.082619   5.367427  141.571026   \n",
       "\n",
       "            w          ma        ad         n            tp        tp_cal  \\\n",
       "0   73.597695   77.372098  2.979647  0.213885  2.458239e+06  2.018043e+07   \n",
       "1  310.202392  144.975675  3.411748  0.213345  2.458321e+06  2.018072e+07   \n",
       "2  248.066193  125.435355  3.353865  0.226129  2.458446e+06  2.018112e+07   \n",
       "3  150.728541   95.861938  2.570926  0.271609  2.458248e+06  2.018051e+07   \n",
       "4  358.648418   17.846343  3.065455  0.238661  2.458926e+06  2.020032e+07   \n",
       "\n",
       "           per     per_y     moid     moid_ld       sigma_e       sigma_a  \\\n",
       "0  1683.145703  4.608202  1.59478  620.640533  4.819000e-12  1.032800e-11   \n",
       "1  1687.410992  4.619880  1.23429  480.348639  3.193400e-08  4.033700e-09   \n",
       "2  1592.013769  4.358696  1.03429  402.514639  3.052000e-08  3.471800e-09   \n",
       "3  1325.432763  3.628837  1.13948  443.451432  2.332100e-10  1.514300e-09   \n",
       "4  1508.414421  4.129814  1.09575  426.433027  2.373700e-08  3.970900e-09   \n",
       "\n",
       "        sigma_q       sigma_i      sigma_om       sigma_w      sigma_ma  \\\n",
       "0  1.956900e-11  4.608900e-09  6.168800e-08  6.624800e-08  7.820700e-09   \n",
       "1  8.832200e-08  3.469400e-06  6.272400e-06  9.128200e-06  8.859100e-06   \n",
       "2  8.139200e-08  3.223100e-06  1.664600e-05  1.772100e-05  8.110400e-06   \n",
       "3  1.928600e-09  2.170600e-07  3.880800e-07  1.789300e-07  1.206800e-06   \n",
       "4  6.092400e-08  2.740800e-06  2.894900e-05  2.984200e-05  8.303800e-06   \n",
       "\n",
       "       sigma_ad       sigma_n      sigma_tp     sigma_per class      rms  \n",
       "0  1.111300e-11  1.196500e-12  3.782900e-08  9.415900e-09   MBA  0.43301  \n",
       "1  4.961300e-09  4.653600e-10  4.078700e-05  3.680700e-06   MBA  0.35936  \n",
       "2  4.363900e-09  4.413400e-10  3.528800e-05  3.107200e-06   MBA  0.33848  \n",
       "3  1.648600e-09  2.612500e-10  4.103700e-06  1.274900e-06   MBA  0.39980  \n",
       "4  4.729000e-09  5.522700e-10  3.474300e-05  3.490500e-06   MBA  0.52191  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 958524 entries, 0 to 958523\n",
      "Data columns (total 45 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   id              958524 non-null  object \n",
      " 1   spkid           958524 non-null  int64  \n",
      " 2   full_name       958524 non-null  object \n",
      " 3   pdes            958524 non-null  object \n",
      " 4   name            22064 non-null   object \n",
      " 5   prefix          18 non-null      object \n",
      " 6   neo             958520 non-null  object \n",
      " 7   pha             938603 non-null  object \n",
      " 8   H               952261 non-null  float64\n",
      " 9   diameter        136209 non-null  float64\n",
      " 10  albedo          135103 non-null  float64\n",
      " 11  diameter_sigma  136081 non-null  float64\n",
      " 12  orbit_id        958524 non-null  object \n",
      " 13  epoch           958524 non-null  float64\n",
      " 14  epoch_mjd       958524 non-null  int64  \n",
      " 15  epoch_cal       958524 non-null  float64\n",
      " 16  equinox         958524 non-null  object \n",
      " 17  e               958524 non-null  float64\n",
      " 18  a               958524 non-null  float64\n",
      " 19  q               958524 non-null  float64\n",
      " 20  i               958524 non-null  float64\n",
      " 21  om              958524 non-null  float64\n",
      " 22  w               958524 non-null  float64\n",
      " 23  ma              958523 non-null  float64\n",
      " 24  ad              958520 non-null  float64\n",
      " 25  n               958524 non-null  float64\n",
      " 26  tp              958524 non-null  float64\n",
      " 27  tp_cal          958524 non-null  float64\n",
      " 28  per             958520 non-null  float64\n",
      " 29  per_y           958523 non-null  float64\n",
      " 30  moid            938603 non-null  float64\n",
      " 31  moid_ld         958397 non-null  float64\n",
      " 32  sigma_e         938602 non-null  float64\n",
      " 33  sigma_a         938602 non-null  float64\n",
      " 34  sigma_q         938602 non-null  float64\n",
      " 35  sigma_i         938602 non-null  float64\n",
      " 36  sigma_om        938602 non-null  float64\n",
      " 37  sigma_w         938602 non-null  float64\n",
      " 38  sigma_ma        938602 non-null  float64\n",
      " 39  sigma_ad        938598 non-null  float64\n",
      " 40  sigma_n         938602 non-null  float64\n",
      " 41  sigma_tp        938602 non-null  float64\n",
      " 42  sigma_per       938598 non-null  float64\n",
      " 43  class           958524 non-null  object \n",
      " 44  rms             958522 non-null  float64\n",
      "dtypes: float64(33), int64(2), object(10)\n",
      "memory usage: 329.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nan_counts = df.isnull().sum()\n",
    "\n",
    "# filter the nan_counts Series to include only columns with non-zero NaN counts\n",
    "nan_counts_filtered = nan_counts[nan_counts > 0]\n",
    "\n",
    "# create a bar chart of the filtered NaN counts\n",
    "plt.figure(figsize=(18, 7))\n",
    "nan_counts_filtered.plot(kind='bar')\n",
    "plt.title('Number of NaN Values by Column')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Number of NaN Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values:\n",
      " name              97.698128\n",
      "prefix            99.998122\n",
      "neo                0.000417\n",
      "pha                2.078300\n",
      "H                  0.653400\n",
      "diameter          85.789714\n",
      "albedo            85.905100\n",
      "diameter_sigma    85.803068\n",
      "ma                 0.000104\n",
      "ad                 0.000417\n",
      "per                0.000417\n",
      "per_y              0.000104\n",
      "moid               2.078300\n",
      "moid_ld            0.013250\n",
      "sigma_e            2.078404\n",
      "sigma_a            2.078404\n",
      "sigma_q            2.078404\n",
      "sigma_i            2.078404\n",
      "sigma_om           2.078404\n",
      "sigma_w            2.078404\n",
      "sigma_ma           2.078404\n",
      "sigma_ad           2.078821\n",
      "sigma_n            2.078404\n",
      "sigma_tp           2.078404\n",
      "sigma_per          2.078821\n",
      "rms                0.000209\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Columns with missing values in Perentage\n",
    "missing_cols = df.isna().mean() * 100\n",
    "missing_cols = missing_cols[missing_cols > 0]\n",
    "print(\"Percentage of missing values:\\n\", missing_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1.  97% of the **name** column is null. Since the **full_name** column includes **pdes** and **name** and no null in this column, pdes and name columns could be removed.\n",
    " \n",
    " 2. prefix refers to asteroid prefix and 99.9% of this column is null. It could be removed because it does not contribute on EDA or modeling.\n",
    " \n",
    "3. About 86% null in each **diameter, albedo, and diameter_sigma** column. These attributes descripe the size of asteriod, and **H**, which refer to absolute magnitude parameter, could descripe the size of asteriod too. Additional, values in these three columns are specific to each unique asteroid, and replacing mean or median will lead to inaccurate subsequent analysis and model construction. Thus, removing **diameter, albedo, and diameter_sigma** column.\n",
    " \n",
    "4. For Columns which has around 2% missing values, we/ are gonna fill them with Random Sample Imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the column which will not facilitate the analysis\n",
    "no_null_data=df.drop(['pdes', 'name', 'prefix', 'diameter', 'albedo', 'diameter_sigma'], axis=1)\n",
    "\n",
    "# Remove the row that includes null value\n",
    "no_null_data=no_null_data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column data type\n",
    "no_null_data['spkid'] = no_null_data['spkid'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save no null dataset in csv for preparing EDA\n",
    "no_null_data.to_csv('no_null_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Columns Dropped\n",
    "# df=df.drop(labels=['prefix','name','diameter','albedo','diameter_sigma','H', 'pdes'], axis=1)\n",
    "\n",
    "# # Random Sample Imputation\n",
    "# def imputer_New(df):\n",
    "#     for col in df.columns:\n",
    "#         if df[col].isnull().sum() > 0:\n",
    "#             random_sample = df[col].dropna().sample(df[col].isnull().sum(),\n",
    "#                                                     random_state=69, replace=True)\n",
    "#             random_sample.index = df[df[col].isnull()].index\n",
    "#             df.loc[df[col].isnull(), col] = random_sample\n",
    "#     return df\n",
    "\n",
    "\n",
    "# imputer_New(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting pha into 0 and 1, Since Ml Algorithms work much better on Numerical Values, 0 would be indicating that the asteroid is not harmful and 1 would indicate it is harmful\n",
    "# df['pha'] = df['pha'].map({\n",
    "\n",
    "#     'N': 0,\n",
    "#     'Y': '1'\n",
    "# })\n",
    "# df['neo'] = df['neo'].map({\n",
    "#     'N':0,\n",
    "#     'Y':'1'\n",
    "\n",
    "# })\n",
    "\n",
    "# # Converting Object to String\n",
    "# df['pha'] = df['pha'].astype(int)\n",
    "# df['spkid'] = df['spkid'].astype(int)\n",
    "# df['neo'] = df['neo'].astype(int)\n",
    "\n",
    "# Segregating Categorical and Numerical Columns\n",
    "df_categorical = df.select_dtypes(include='object')\n",
    "df_numerical=df.select_dtypes(include='number')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expolatory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spkid</th>\n",
       "      <th>H</th>\n",
       "      <th>diameter</th>\n",
       "      <th>albedo</th>\n",
       "      <th>diameter_sigma</th>\n",
       "      <th>epoch</th>\n",
       "      <th>epoch_mjd</th>\n",
       "      <th>epoch_cal</th>\n",
       "      <th>e</th>\n",
       "      <th>a</th>\n",
       "      <th>q</th>\n",
       "      <th>i</th>\n",
       "      <th>om</th>\n",
       "      <th>w</th>\n",
       "      <th>ma</th>\n",
       "      <th>ad</th>\n",
       "      <th>n</th>\n",
       "      <th>tp</th>\n",
       "      <th>tp_cal</th>\n",
       "      <th>per</th>\n",
       "      <th>per_y</th>\n",
       "      <th>moid</th>\n",
       "      <th>moid_ld</th>\n",
       "      <th>sigma_e</th>\n",
       "      <th>sigma_a</th>\n",
       "      <th>sigma_q</th>\n",
       "      <th>sigma_i</th>\n",
       "      <th>sigma_om</th>\n",
       "      <th>sigma_w</th>\n",
       "      <th>sigma_ma</th>\n",
       "      <th>sigma_ad</th>\n",
       "      <th>sigma_n</th>\n",
       "      <th>sigma_tp</th>\n",
       "      <th>sigma_per</th>\n",
       "      <th>rms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000001</td>\n",
       "      <td>3.40</td>\n",
       "      <td>939.400</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.200</td>\n",
       "      <td>2458600.5</td>\n",
       "      <td>58600</td>\n",
       "      <td>20190427.0</td>\n",
       "      <td>0.076009</td>\n",
       "      <td>2.769165</td>\n",
       "      <td>2.558684</td>\n",
       "      <td>10.594067</td>\n",
       "      <td>80.305531</td>\n",
       "      <td>73.597695</td>\n",
       "      <td>77.372098</td>\n",
       "      <td>2.979647</td>\n",
       "      <td>0.213885</td>\n",
       "      <td>2.458239e+06</td>\n",
       "      <td>2.018043e+07</td>\n",
       "      <td>1683.145703</td>\n",
       "      <td>4.608202</td>\n",
       "      <td>1.59478</td>\n",
       "      <td>620.640533</td>\n",
       "      <td>4.819000e-12</td>\n",
       "      <td>1.032800e-11</td>\n",
       "      <td>1.956900e-11</td>\n",
       "      <td>4.608900e-09</td>\n",
       "      <td>6.168800e-08</td>\n",
       "      <td>6.624800e-08</td>\n",
       "      <td>7.820700e-09</td>\n",
       "      <td>1.111300e-11</td>\n",
       "      <td>1.196500e-12</td>\n",
       "      <td>3.782900e-08</td>\n",
       "      <td>9.415900e-09</td>\n",
       "      <td>0.43301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000002</td>\n",
       "      <td>4.20</td>\n",
       "      <td>545.000</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>18.000</td>\n",
       "      <td>2459000.5</td>\n",
       "      <td>59000</td>\n",
       "      <td>20200531.0</td>\n",
       "      <td>0.229972</td>\n",
       "      <td>2.773841</td>\n",
       "      <td>2.135935</td>\n",
       "      <td>34.832932</td>\n",
       "      <td>173.024741</td>\n",
       "      <td>310.202392</td>\n",
       "      <td>144.975675</td>\n",
       "      <td>3.411748</td>\n",
       "      <td>0.213345</td>\n",
       "      <td>2.458321e+06</td>\n",
       "      <td>2.018072e+07</td>\n",
       "      <td>1687.410992</td>\n",
       "      <td>4.619880</td>\n",
       "      <td>1.23429</td>\n",
       "      <td>480.348639</td>\n",
       "      <td>3.193400e-08</td>\n",
       "      <td>4.033700e-09</td>\n",
       "      <td>8.832200e-08</td>\n",
       "      <td>3.469400e-06</td>\n",
       "      <td>6.272400e-06</td>\n",
       "      <td>9.128200e-06</td>\n",
       "      <td>8.859100e-06</td>\n",
       "      <td>4.961300e-09</td>\n",
       "      <td>4.653600e-10</td>\n",
       "      <td>4.078700e-05</td>\n",
       "      <td>3.680700e-06</td>\n",
       "      <td>0.35936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000003</td>\n",
       "      <td>5.33</td>\n",
       "      <td>246.596</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>10.594</td>\n",
       "      <td>2459000.5</td>\n",
       "      <td>59000</td>\n",
       "      <td>20200531.0</td>\n",
       "      <td>0.256936</td>\n",
       "      <td>2.668285</td>\n",
       "      <td>1.982706</td>\n",
       "      <td>12.991043</td>\n",
       "      <td>169.851482</td>\n",
       "      <td>248.066193</td>\n",
       "      <td>125.435355</td>\n",
       "      <td>3.353865</td>\n",
       "      <td>0.226129</td>\n",
       "      <td>2.458446e+06</td>\n",
       "      <td>2.018112e+07</td>\n",
       "      <td>1592.013769</td>\n",
       "      <td>4.358696</td>\n",
       "      <td>1.03429</td>\n",
       "      <td>402.514639</td>\n",
       "      <td>3.052000e-08</td>\n",
       "      <td>3.471800e-09</td>\n",
       "      <td>8.139200e-08</td>\n",
       "      <td>3.223100e-06</td>\n",
       "      <td>1.664600e-05</td>\n",
       "      <td>1.772100e-05</td>\n",
       "      <td>8.110400e-06</td>\n",
       "      <td>4.363900e-09</td>\n",
       "      <td>4.413400e-10</td>\n",
       "      <td>3.528800e-05</td>\n",
       "      <td>3.107200e-06</td>\n",
       "      <td>0.33848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000004</td>\n",
       "      <td>3.00</td>\n",
       "      <td>525.400</td>\n",
       "      <td>0.4228</td>\n",
       "      <td>0.200</td>\n",
       "      <td>2458600.5</td>\n",
       "      <td>58600</td>\n",
       "      <td>20190427.0</td>\n",
       "      <td>0.088721</td>\n",
       "      <td>2.361418</td>\n",
       "      <td>2.151909</td>\n",
       "      <td>7.141771</td>\n",
       "      <td>103.810804</td>\n",
       "      <td>150.728541</td>\n",
       "      <td>95.861938</td>\n",
       "      <td>2.570926</td>\n",
       "      <td>0.271609</td>\n",
       "      <td>2.458248e+06</td>\n",
       "      <td>2.018051e+07</td>\n",
       "      <td>1325.432763</td>\n",
       "      <td>3.628837</td>\n",
       "      <td>1.13948</td>\n",
       "      <td>443.451432</td>\n",
       "      <td>2.332100e-10</td>\n",
       "      <td>1.514300e-09</td>\n",
       "      <td>1.928600e-09</td>\n",
       "      <td>2.170600e-07</td>\n",
       "      <td>3.880800e-07</td>\n",
       "      <td>1.789300e-07</td>\n",
       "      <td>1.206800e-06</td>\n",
       "      <td>1.648600e-09</td>\n",
       "      <td>2.612500e-10</td>\n",
       "      <td>4.103700e-06</td>\n",
       "      <td>1.274900e-06</td>\n",
       "      <td>0.39980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000005</td>\n",
       "      <td>6.90</td>\n",
       "      <td>106.699</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>3.140</td>\n",
       "      <td>2459000.5</td>\n",
       "      <td>59000</td>\n",
       "      <td>20200531.0</td>\n",
       "      <td>0.190913</td>\n",
       "      <td>2.574037</td>\n",
       "      <td>2.082619</td>\n",
       "      <td>5.367427</td>\n",
       "      <td>141.571026</td>\n",
       "      <td>358.648418</td>\n",
       "      <td>17.846343</td>\n",
       "      <td>3.065455</td>\n",
       "      <td>0.238661</td>\n",
       "      <td>2.458926e+06</td>\n",
       "      <td>2.020032e+07</td>\n",
       "      <td>1508.414421</td>\n",
       "      <td>4.129814</td>\n",
       "      <td>1.09575</td>\n",
       "      <td>426.433027</td>\n",
       "      <td>2.373700e-08</td>\n",
       "      <td>3.970900e-09</td>\n",
       "      <td>6.092400e-08</td>\n",
       "      <td>2.740800e-06</td>\n",
       "      <td>2.894900e-05</td>\n",
       "      <td>2.984200e-05</td>\n",
       "      <td>8.303800e-06</td>\n",
       "      <td>4.729000e-09</td>\n",
       "      <td>5.522700e-10</td>\n",
       "      <td>3.474300e-05</td>\n",
       "      <td>3.490500e-06</td>\n",
       "      <td>0.52191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     spkid     H  diameter  albedo  diameter_sigma      epoch  epoch_mjd  \\\n",
       "0  2000001  3.40   939.400  0.0900           0.200  2458600.5      58600   \n",
       "1  2000002  4.20   545.000  0.1010          18.000  2459000.5      59000   \n",
       "2  2000003  5.33   246.596  0.2140          10.594  2459000.5      59000   \n",
       "3  2000004  3.00   525.400  0.4228           0.200  2458600.5      58600   \n",
       "4  2000005  6.90   106.699  0.2740           3.140  2459000.5      59000   \n",
       "\n",
       "    epoch_cal         e         a         q          i          om  \\\n",
       "0  20190427.0  0.076009  2.769165  2.558684  10.594067   80.305531   \n",
       "1  20200531.0  0.229972  2.773841  2.135935  34.832932  173.024741   \n",
       "2  20200531.0  0.256936  2.668285  1.982706  12.991043  169.851482   \n",
       "3  20190427.0  0.088721  2.361418  2.151909   7.141771  103.810804   \n",
       "4  20200531.0  0.190913  2.574037  2.082619   5.367427  141.571026   \n",
       "\n",
       "            w          ma        ad         n            tp        tp_cal  \\\n",
       "0   73.597695   77.372098  2.979647  0.213885  2.458239e+06  2.018043e+07   \n",
       "1  310.202392  144.975675  3.411748  0.213345  2.458321e+06  2.018072e+07   \n",
       "2  248.066193  125.435355  3.353865  0.226129  2.458446e+06  2.018112e+07   \n",
       "3  150.728541   95.861938  2.570926  0.271609  2.458248e+06  2.018051e+07   \n",
       "4  358.648418   17.846343  3.065455  0.238661  2.458926e+06  2.020032e+07   \n",
       "\n",
       "           per     per_y     moid     moid_ld       sigma_e       sigma_a  \\\n",
       "0  1683.145703  4.608202  1.59478  620.640533  4.819000e-12  1.032800e-11   \n",
       "1  1687.410992  4.619880  1.23429  480.348639  3.193400e-08  4.033700e-09   \n",
       "2  1592.013769  4.358696  1.03429  402.514639  3.052000e-08  3.471800e-09   \n",
       "3  1325.432763  3.628837  1.13948  443.451432  2.332100e-10  1.514300e-09   \n",
       "4  1508.414421  4.129814  1.09575  426.433027  2.373700e-08  3.970900e-09   \n",
       "\n",
       "        sigma_q       sigma_i      sigma_om       sigma_w      sigma_ma  \\\n",
       "0  1.956900e-11  4.608900e-09  6.168800e-08  6.624800e-08  7.820700e-09   \n",
       "1  8.832200e-08  3.469400e-06  6.272400e-06  9.128200e-06  8.859100e-06   \n",
       "2  8.139200e-08  3.223100e-06  1.664600e-05  1.772100e-05  8.110400e-06   \n",
       "3  1.928600e-09  2.170600e-07  3.880800e-07  1.789300e-07  1.206800e-06   \n",
       "4  6.092400e-08  2.740800e-06  2.894900e-05  2.984200e-05  8.303800e-06   \n",
       "\n",
       "       sigma_ad       sigma_n      sigma_tp     sigma_per      rms  \n",
       "0  1.111300e-11  1.196500e-12  3.782900e-08  9.415900e-09  0.43301  \n",
       "1  4.961300e-09  4.653600e-10  4.078700e-05  3.680700e-06  0.35936  \n",
       "2  4.363900e-09  4.413400e-10  3.528800e-05  3.107200e-06  0.33848  \n",
       "3  1.648600e-09  2.612500e-10  4.103700e-06  1.274900e-06  0.39980  \n",
       "4  4.729000e-09  5.522700e-10  3.474300e-05  3.490500e-06  0.52191  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_numerical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_name</th>\n",
       "      <th>pdes</th>\n",
       "      <th>name</th>\n",
       "      <th>prefix</th>\n",
       "      <th>neo</th>\n",
       "      <th>pha</th>\n",
       "      <th>orbit_id</th>\n",
       "      <th>equinox</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a0000001</td>\n",
       "      <td>1 Ceres</td>\n",
       "      <td>1</td>\n",
       "      <td>Ceres</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>JPL 47</td>\n",
       "      <td>J2000</td>\n",
       "      <td>MBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a0000002</td>\n",
       "      <td>2 Pallas</td>\n",
       "      <td>2</td>\n",
       "      <td>Pallas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>JPL 37</td>\n",
       "      <td>J2000</td>\n",
       "      <td>MBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a0000003</td>\n",
       "      <td>3 Juno</td>\n",
       "      <td>3</td>\n",
       "      <td>Juno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>JPL 112</td>\n",
       "      <td>J2000</td>\n",
       "      <td>MBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a0000004</td>\n",
       "      <td>4 Vesta</td>\n",
       "      <td>4</td>\n",
       "      <td>Vesta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>JPL 35</td>\n",
       "      <td>J2000</td>\n",
       "      <td>MBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a0000005</td>\n",
       "      <td>5 Astraea</td>\n",
       "      <td>5</td>\n",
       "      <td>Astraea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>JPL 114</td>\n",
       "      <td>J2000</td>\n",
       "      <td>MBA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       full_name pdes     name prefix neo pha orbit_id equinox  \\\n",
       "0  a0000001         1 Ceres    1    Ceres    NaN   N   N   JPL 47   J2000   \n",
       "1  a0000002        2 Pallas    2   Pallas    NaN   N   N   JPL 37   J2000   \n",
       "2  a0000003          3 Juno    3     Juno    NaN   N   N  JPL 112   J2000   \n",
       "3  a0000004         4 Vesta    4    Vesta    NaN   N   N   JPL 35   J2000   \n",
       "4  a0000005       5 Astraea    5  Astraea    NaN   N   N  JPL 114   J2000   \n",
       "\n",
       "  class  \n",
       "0   MBA  \n",
       "1   MBA  \n",
       "2   MBA  \n",
       "3   MBA  \n",
       "4   MBA  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Figure with two subplots\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "#  Count plot of the \"neo\" variable on the left subplot\n",
    "sns.countplot(x='neo', data=df, ax=axs[0])\n",
    "axs[0].set_title('Near Earth Objects')\n",
    "\n",
    "# Add percentage labels to the left subplot\n",
    "total = float(len(df.neo))\n",
    "for p in axs[0].patches:\n",
    "    percentage = '{:.1f}%'.format(100 * p.get_height()/total)\n",
    "    x = p.get_x() + p.get_width() / 2 - 0.1\n",
    "    y = p.get_y() + p.get_height() + 3\n",
    "    axs[0].annotate(percentage, (x, y))\n",
    "\n",
    "#  Count plot of the \"pha\" variable on the right subplot\n",
    "sns.countplot(x='pha', data=df, ax=axs[1])\n",
    "axs[1].set_title('Potentially Hazardous Asteroids')\n",
    "\n",
    "# Add percentage labels to the right subplot\n",
    "total = float(len(df.pha))\n",
    "for p in axs[1].patches:\n",
    "    percentage = '{:.1f}%'.format(100 * p.get_height()/total)\n",
    "    x = p.get_x() + p.get_width() / 2 - 0.1\n",
    "    y = p.get_y() + p.get_height() + 3\n",
    "    axs[1].annotate(percentage, (x, y))\n",
    "\n",
    "# Adjust the spacing between the subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Count plot for Orbit Class\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "sns.countplot(x='class', data=df, ax=ax)\n",
    "plt.title('Orbit Class')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset is highly unbalanced, 2.4% are **Near Earth Objects** and out of those only **0.2%** are Hazaerdous Asteriods\n",
    "\n",
    "-  Out of 12 Orbit classes most of the orbit class is  of  **MBA** , which is around **89%.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "\n",
    "# Remove identifying columns\n",
    "data=no_null_data.drop(['id', 'spkid', 'full_name', 'orbit_id', 'equinox'], axis=1).reset_index(drop=True)\n",
    "\n",
    "# Encode categorical features and target\n",
    "one_hot_encoded_data = pd.get_dummies(data, columns=['neo', 'class'])\n",
    "one_hot_encoded_data['pha'] = LabelEncoder(\n",
    ").fit_transform(one_hot_encoded_data['pha'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pha</th>\n",
       "      <th>H</th>\n",
       "      <th>epoch</th>\n",
       "      <th>epoch_mjd</th>\n",
       "      <th>epoch_cal</th>\n",
       "      <th>e</th>\n",
       "      <th>a</th>\n",
       "      <th>q</th>\n",
       "      <th>i</th>\n",
       "      <th>om</th>\n",
       "      <th>w</th>\n",
       "      <th>ma</th>\n",
       "      <th>ad</th>\n",
       "      <th>n</th>\n",
       "      <th>tp</th>\n",
       "      <th>tp_cal</th>\n",
       "      <th>per</th>\n",
       "      <th>per_y</th>\n",
       "      <th>moid</th>\n",
       "      <th>moid_ld</th>\n",
       "      <th>sigma_e</th>\n",
       "      <th>sigma_a</th>\n",
       "      <th>sigma_q</th>\n",
       "      <th>sigma_i</th>\n",
       "      <th>sigma_om</th>\n",
       "      <th>sigma_w</th>\n",
       "      <th>sigma_ma</th>\n",
       "      <th>sigma_ad</th>\n",
       "      <th>sigma_n</th>\n",
       "      <th>sigma_tp</th>\n",
       "      <th>sigma_per</th>\n",
       "      <th>rms</th>\n",
       "      <th>neo_N</th>\n",
       "      <th>neo_Y</th>\n",
       "      <th>class_AMO</th>\n",
       "      <th>class_APO</th>\n",
       "      <th>class_AST</th>\n",
       "      <th>class_ATE</th>\n",
       "      <th>class_CEN</th>\n",
       "      <th>class_IEO</th>\n",
       "      <th>class_IMB</th>\n",
       "      <th>class_MBA</th>\n",
       "      <th>class_MCA</th>\n",
       "      <th>class_OMB</th>\n",
       "      <th>class_TJN</th>\n",
       "      <th>class_TNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2458600.5</td>\n",
       "      <td>58600</td>\n",
       "      <td>20190427.0</td>\n",
       "      <td>0.076009</td>\n",
       "      <td>2.769165</td>\n",
       "      <td>2.558684</td>\n",
       "      <td>10.594067</td>\n",
       "      <td>80.305531</td>\n",
       "      <td>73.597695</td>\n",
       "      <td>77.372098</td>\n",
       "      <td>2.979647</td>\n",
       "      <td>0.213885</td>\n",
       "      <td>2.458239e+06</td>\n",
       "      <td>2.018043e+07</td>\n",
       "      <td>1683.145703</td>\n",
       "      <td>4.608202</td>\n",
       "      <td>1.59478</td>\n",
       "      <td>620.640533</td>\n",
       "      <td>4.819000e-12</td>\n",
       "      <td>1.032800e-11</td>\n",
       "      <td>1.956900e-11</td>\n",
       "      <td>4.608900e-09</td>\n",
       "      <td>6.168800e-08</td>\n",
       "      <td>6.624800e-08</td>\n",
       "      <td>7.820700e-09</td>\n",
       "      <td>1.111300e-11</td>\n",
       "      <td>1.196500e-12</td>\n",
       "      <td>3.782900e-08</td>\n",
       "      <td>9.415900e-09</td>\n",
       "      <td>0.43301</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>2459000.5</td>\n",
       "      <td>59000</td>\n",
       "      <td>20200531.0</td>\n",
       "      <td>0.229972</td>\n",
       "      <td>2.773841</td>\n",
       "      <td>2.135935</td>\n",
       "      <td>34.832932</td>\n",
       "      <td>173.024741</td>\n",
       "      <td>310.202392</td>\n",
       "      <td>144.975675</td>\n",
       "      <td>3.411748</td>\n",
       "      <td>0.213345</td>\n",
       "      <td>2.458321e+06</td>\n",
       "      <td>2.018072e+07</td>\n",
       "      <td>1687.410992</td>\n",
       "      <td>4.619880</td>\n",
       "      <td>1.23429</td>\n",
       "      <td>480.348639</td>\n",
       "      <td>3.193400e-08</td>\n",
       "      <td>4.033700e-09</td>\n",
       "      <td>8.832200e-08</td>\n",
       "      <td>3.469400e-06</td>\n",
       "      <td>6.272400e-06</td>\n",
       "      <td>9.128200e-06</td>\n",
       "      <td>8.859100e-06</td>\n",
       "      <td>4.961300e-09</td>\n",
       "      <td>4.653600e-10</td>\n",
       "      <td>4.078700e-05</td>\n",
       "      <td>3.680700e-06</td>\n",
       "      <td>0.35936</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5.33</td>\n",
       "      <td>2459000.5</td>\n",
       "      <td>59000</td>\n",
       "      <td>20200531.0</td>\n",
       "      <td>0.256936</td>\n",
       "      <td>2.668285</td>\n",
       "      <td>1.982706</td>\n",
       "      <td>12.991043</td>\n",
       "      <td>169.851482</td>\n",
       "      <td>248.066193</td>\n",
       "      <td>125.435355</td>\n",
       "      <td>3.353865</td>\n",
       "      <td>0.226129</td>\n",
       "      <td>2.458446e+06</td>\n",
       "      <td>2.018112e+07</td>\n",
       "      <td>1592.013769</td>\n",
       "      <td>4.358696</td>\n",
       "      <td>1.03429</td>\n",
       "      <td>402.514639</td>\n",
       "      <td>3.052000e-08</td>\n",
       "      <td>3.471800e-09</td>\n",
       "      <td>8.139200e-08</td>\n",
       "      <td>3.223100e-06</td>\n",
       "      <td>1.664600e-05</td>\n",
       "      <td>1.772100e-05</td>\n",
       "      <td>8.110400e-06</td>\n",
       "      <td>4.363900e-09</td>\n",
       "      <td>4.413400e-10</td>\n",
       "      <td>3.528800e-05</td>\n",
       "      <td>3.107200e-06</td>\n",
       "      <td>0.33848</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2458600.5</td>\n",
       "      <td>58600</td>\n",
       "      <td>20190427.0</td>\n",
       "      <td>0.088721</td>\n",
       "      <td>2.361418</td>\n",
       "      <td>2.151909</td>\n",
       "      <td>7.141771</td>\n",
       "      <td>103.810804</td>\n",
       "      <td>150.728541</td>\n",
       "      <td>95.861938</td>\n",
       "      <td>2.570926</td>\n",
       "      <td>0.271609</td>\n",
       "      <td>2.458248e+06</td>\n",
       "      <td>2.018051e+07</td>\n",
       "      <td>1325.432763</td>\n",
       "      <td>3.628837</td>\n",
       "      <td>1.13948</td>\n",
       "      <td>443.451432</td>\n",
       "      <td>2.332100e-10</td>\n",
       "      <td>1.514300e-09</td>\n",
       "      <td>1.928600e-09</td>\n",
       "      <td>2.170600e-07</td>\n",
       "      <td>3.880800e-07</td>\n",
       "      <td>1.789300e-07</td>\n",
       "      <td>1.206800e-06</td>\n",
       "      <td>1.648600e-09</td>\n",
       "      <td>2.612500e-10</td>\n",
       "      <td>4.103700e-06</td>\n",
       "      <td>1.274900e-06</td>\n",
       "      <td>0.39980</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6.90</td>\n",
       "      <td>2459000.5</td>\n",
       "      <td>59000</td>\n",
       "      <td>20200531.0</td>\n",
       "      <td>0.190913</td>\n",
       "      <td>2.574037</td>\n",
       "      <td>2.082619</td>\n",
       "      <td>5.367427</td>\n",
       "      <td>141.571026</td>\n",
       "      <td>358.648418</td>\n",
       "      <td>17.846343</td>\n",
       "      <td>3.065455</td>\n",
       "      <td>0.238661</td>\n",
       "      <td>2.458926e+06</td>\n",
       "      <td>2.020032e+07</td>\n",
       "      <td>1508.414421</td>\n",
       "      <td>4.129814</td>\n",
       "      <td>1.09575</td>\n",
       "      <td>426.433027</td>\n",
       "      <td>2.373700e-08</td>\n",
       "      <td>3.970900e-09</td>\n",
       "      <td>6.092400e-08</td>\n",
       "      <td>2.740800e-06</td>\n",
       "      <td>2.894900e-05</td>\n",
       "      <td>2.984200e-05</td>\n",
       "      <td>8.303800e-06</td>\n",
       "      <td>4.729000e-09</td>\n",
       "      <td>5.522700e-10</td>\n",
       "      <td>3.474300e-05</td>\n",
       "      <td>3.490500e-06</td>\n",
       "      <td>0.52191</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pha     H      epoch  epoch_mjd   epoch_cal         e         a         q  \\\n",
       "0    0  3.40  2458600.5      58600  20190427.0  0.076009  2.769165  2.558684   \n",
       "1    0  4.20  2459000.5      59000  20200531.0  0.229972  2.773841  2.135935   \n",
       "2    0  5.33  2459000.5      59000  20200531.0  0.256936  2.668285  1.982706   \n",
       "3    0  3.00  2458600.5      58600  20190427.0  0.088721  2.361418  2.151909   \n",
       "4    0  6.90  2459000.5      59000  20200531.0  0.190913  2.574037  2.082619   \n",
       "\n",
       "           i          om           w          ma        ad         n  \\\n",
       "0  10.594067   80.305531   73.597695   77.372098  2.979647  0.213885   \n",
       "1  34.832932  173.024741  310.202392  144.975675  3.411748  0.213345   \n",
       "2  12.991043  169.851482  248.066193  125.435355  3.353865  0.226129   \n",
       "3   7.141771  103.810804  150.728541   95.861938  2.570926  0.271609   \n",
       "4   5.367427  141.571026  358.648418   17.846343  3.065455  0.238661   \n",
       "\n",
       "             tp        tp_cal          per     per_y     moid     moid_ld  \\\n",
       "0  2.458239e+06  2.018043e+07  1683.145703  4.608202  1.59478  620.640533   \n",
       "1  2.458321e+06  2.018072e+07  1687.410992  4.619880  1.23429  480.348639   \n",
       "2  2.458446e+06  2.018112e+07  1592.013769  4.358696  1.03429  402.514639   \n",
       "3  2.458248e+06  2.018051e+07  1325.432763  3.628837  1.13948  443.451432   \n",
       "4  2.458926e+06  2.020032e+07  1508.414421  4.129814  1.09575  426.433027   \n",
       "\n",
       "        sigma_e       sigma_a       sigma_q       sigma_i      sigma_om  \\\n",
       "0  4.819000e-12  1.032800e-11  1.956900e-11  4.608900e-09  6.168800e-08   \n",
       "1  3.193400e-08  4.033700e-09  8.832200e-08  3.469400e-06  6.272400e-06   \n",
       "2  3.052000e-08  3.471800e-09  8.139200e-08  3.223100e-06  1.664600e-05   \n",
       "3  2.332100e-10  1.514300e-09  1.928600e-09  2.170600e-07  3.880800e-07   \n",
       "4  2.373700e-08  3.970900e-09  6.092400e-08  2.740800e-06  2.894900e-05   \n",
       "\n",
       "        sigma_w      sigma_ma      sigma_ad       sigma_n      sigma_tp  \\\n",
       "0  6.624800e-08  7.820700e-09  1.111300e-11  1.196500e-12  3.782900e-08   \n",
       "1  9.128200e-06  8.859100e-06  4.961300e-09  4.653600e-10  4.078700e-05   \n",
       "2  1.772100e-05  8.110400e-06  4.363900e-09  4.413400e-10  3.528800e-05   \n",
       "3  1.789300e-07  1.206800e-06  1.648600e-09  2.612500e-10  4.103700e-06   \n",
       "4  2.984200e-05  8.303800e-06  4.729000e-09  5.522700e-10  3.474300e-05   \n",
       "\n",
       "      sigma_per      rms  neo_N  neo_Y  class_AMO  class_APO  class_AST  \\\n",
       "0  9.415900e-09  0.43301      1      0          0          0          0   \n",
       "1  3.680700e-06  0.35936      1      0          0          0          0   \n",
       "2  3.107200e-06  0.33848      1      0          0          0          0   \n",
       "3  1.274900e-06  0.39980      1      0          0          0          0   \n",
       "4  3.490500e-06  0.52191      1      0          0          0          0   \n",
       "\n",
       "   class_ATE  class_CEN  class_IEO  class_IMB  class_MBA  class_MCA  \\\n",
       "0          0          0          0          0          1          0   \n",
       "1          0          0          0          0          1          0   \n",
       "2          0          0          0          0          1          0   \n",
       "3          0          0          0          0          1          0   \n",
       "4          0          0          0          0          1          0   \n",
       "\n",
       "   class_OMB  class_TJN  class_TNO  \n",
       "0          0          0          0  \n",
       "1          0          0          0  \n",
       "2          0          0          0  \n",
       "3          0          0          0  \n",
       "4          0          0          0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 932335 entries, 0 to 932334\n",
      "Data columns (total 46 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   pha        932335 non-null  int64  \n",
      " 1   H          932335 non-null  float64\n",
      " 2   epoch      932335 non-null  float64\n",
      " 3   epoch_mjd  932335 non-null  int64  \n",
      " 4   epoch_cal  932335 non-null  float64\n",
      " 5   e          932335 non-null  float64\n",
      " 6   a          932335 non-null  float64\n",
      " 7   q          932335 non-null  float64\n",
      " 8   i          932335 non-null  float64\n",
      " 9   om         932335 non-null  float64\n",
      " 10  w          932335 non-null  float64\n",
      " 11  ma         932335 non-null  float64\n",
      " 12  ad         932335 non-null  float64\n",
      " 13  n          932335 non-null  float64\n",
      " 14  tp         932335 non-null  float64\n",
      " 15  tp_cal     932335 non-null  float64\n",
      " 16  per        932335 non-null  float64\n",
      " 17  per_y      932335 non-null  float64\n",
      " 18  moid       932335 non-null  float64\n",
      " 19  moid_ld    932335 non-null  float64\n",
      " 20  sigma_e    932335 non-null  float64\n",
      " 21  sigma_a    932335 non-null  float64\n",
      " 22  sigma_q    932335 non-null  float64\n",
      " 23  sigma_i    932335 non-null  float64\n",
      " 24  sigma_om   932335 non-null  float64\n",
      " 25  sigma_w    932335 non-null  float64\n",
      " 26  sigma_ma   932335 non-null  float64\n",
      " 27  sigma_ad   932335 non-null  float64\n",
      " 28  sigma_n    932335 non-null  float64\n",
      " 29  sigma_tp   932335 non-null  float64\n",
      " 30  sigma_per  932335 non-null  float64\n",
      " 31  rms        932335 non-null  float64\n",
      " 32  neo_N      932335 non-null  uint8  \n",
      " 33  neo_Y      932335 non-null  uint8  \n",
      " 34  class_AMO  932335 non-null  uint8  \n",
      " 35  class_APO  932335 non-null  uint8  \n",
      " 36  class_AST  932335 non-null  uint8  \n",
      " 37  class_ATE  932335 non-null  uint8  \n",
      " 38  class_CEN  932335 non-null  uint8  \n",
      " 39  class_IEO  932335 non-null  uint8  \n",
      " 40  class_IMB  932335 non-null  uint8  \n",
      " 41  class_MBA  932335 non-null  uint8  \n",
      " 42  class_MCA  932335 non-null  uint8  \n",
      " 43  class_OMB  932335 non-null  uint8  \n",
      " 44  class_TJN  932335 non-null  uint8  \n",
      " 45  class_TNO  932335 non-null  uint8  \n",
      "dtypes: float64(30), int64(2), uint8(14)\n",
      "memory usage: 240.1 MB\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoded_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split train, validation, and test sets\n",
    "# x = one_hot_encoded_data.drop('pha', axis=1)\n",
    "# y = one_hot_encoded_data['pha'].to_frame()\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#     x, y, test_size=0.2, random_state=100, stratify=y)\n",
    "\n",
    "# print(\"Shape of original dataset :\", one_hot_encoded_data.shape)\n",
    "# print(\"Shape of x_train set\", x_train.shape)\n",
    "# print(\"Shape of y_train set\", y_train.shape)\n",
    "\n",
    "# print(\"Shape of x_test set\", x_test.shape)\n",
    "# print(\"Shape of y_test set\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original dataset : (932335, 46)\n",
      "Shape of x_train set (559401, 45)\n",
      "Shape of y_train set (559401, 1)\n",
      "Shape of x_validation set (186467, 45)\n",
      "Shape of y_validation set (186467, 1)\n",
      "Shape of x_test set (186467, 45)\n",
      "Shape of y_test set (186467, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split train, validation, and test sets\n",
    "x = one_hot_encoded_data.drop('pha', axis=1)\n",
    "y = one_hot_encoded_data['pha'].to_frame()\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.4, random_state=100, stratify=y)\n",
    "x_val, x_test, y_val, y_test = train_test_split(\n",
    "    x_test, y_test, test_size=0.5, random_state=100, stratify=y_test)\n",
    "print(\"Shape of original dataset :\", one_hot_encoded_data.shape)\n",
    "print(\"Shape of x_train set\", x_train.shape)\n",
    "print(\"Shape of y_train set\", y_train.shape)\n",
    "print(\"Shape of x_validation set\", x_val.shape)\n",
    "print(\"Shape of y_validation set\", y_val.shape)\n",
    "print(\"Shape of x_test set\", x_test.shape)\n",
    "print(\"Shape of y_test set\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalizing the features\n",
    "x_train = StandardScaler().fit_transform(x_train)\n",
    "x_val = StandardScaler().fit_transform(x_val)\n",
    "x_test = StandardScaler().fit_transform(x_test)\n",
    "# Normalizing after splitting could prevent leaking information about the validation set into the train set\n",
    "# StandardScaler() is useful in classification and Normalizer() is useful in regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# # Create a RobustScaler object\n",
    "# scaler = RobustScaler()\n",
    "\n",
    "# # Fit and transform the features\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_val = scaler.transform(x_val)\n",
    "# x_test = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pha\n",
       "0      558161\n",
       "1        1240\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imbalance in target variable\n",
    "y_train.value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed the Imbalancing of the dataset with SMOTE and RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pha\n",
       "0      558161\n",
       "1      279080\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Data Upsampling - SMOTE\n",
    "x_train_us, y_train_us = SMOTE(\n",
    "    sampling_strategy=0.5, random_state=100).fit_resample(x_train, y_train)\n",
    "y_train_us.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pha\n",
       "0      279080\n",
       "1      279080\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Data Undersampling - Random Undersampling\n",
    "random_under_sampling = RandomUnderSampler(random_state=100)\n",
    "x_train_us_rus, y_train_us_rus = random_under_sampling.fit_resample(x_train_us, y_train_us)\n",
    "\n",
    "y_train_us_rus.value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/32/01d39x_s1sn9ywcywln8d29r0000gn/T/ipykernel_28275/175660274.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(x_train_us_rus, y_train_us_rus)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kavach/Documents/Dev/Andrew/Assignmet/original.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kavach/Documents/Dev/Andrew/Assignmet/original.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m rfc \u001b[39m=\u001b[39m RandomForestClassifier(class_weight\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m'\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kavach/Documents/Dev/Andrew/Assignmet/original.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Skip Hyperparameter Tuning part because parameter with dafult value get the highest accuracy of model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kavach/Documents/Dev/Andrew/Assignmet/original.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m rfc\u001b[39m.\u001b[39;49mfit(x_train_us_rus, y_train_us_rus)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kavach/Documents/Dev/Andrew/Assignmet/original.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Predict for validation set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kavach/Documents/Dev/Andrew/Assignmet/original.ipynb#X44sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m y_val_pred \u001b[39m=\u001b[39m rfc\u001b[39m.\u001b[39mpredict(x_val)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    477\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    478\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    479\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    480\u001b[0m )(\n\u001b[1;32m    481\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    482\u001b[0m         t,\n\u001b[1;32m    483\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    484\u001b[0m         X,\n\u001b[1;32m    485\u001b[0m         y,\n\u001b[1;32m    486\u001b[0m         sample_weight,\n\u001b[1;32m    487\u001b[0m         i,\n\u001b[1;32m    488\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    489\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    490\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    491\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    492\u001b[0m     )\n\u001b[1;32m    493\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    494\u001b[0m )\n\u001b[1;32m    496\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    187\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 189\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    190\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:969\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    940\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \n\u001b[1;32m    942\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    970\u001b[0m         X,\n\u001b[1;32m    971\u001b[0m         y,\n\u001b[1;32m    972\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    973\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    975\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(class_weight='balanced', random_state=100)\n",
    "# Skip Hyperparameter Tuning part because parameter with dafult value get the highest accuracy of model\n",
    "\n",
    "rfc.fit(x_train_us_rus, y_train_us_rus)\n",
    "\n",
    "# Predict for validation set\n",
    "y_val_pred = rfc.predict(x_val)\n",
    "\n",
    "# Metrics\n",
    "precision_rfc, recall_rfc, fscore_rfc, support_rfc = precision_recall_fscore_support(\n",
    "    y_val, y_val_pred, average='macro')\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavach/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kavach/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kavach/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kavach/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    186054\n",
      "           1       0.00      0.00      0.00       413\n",
      "\n",
      "    accuracy                           1.00    186467\n",
      "   macro avg       0.50      0.50      0.50    186467\n",
      "weighted avg       1.00      1.00      1.00    186467\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavach/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kavach/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(x_train_us_rus, y_train_us_rus)\n",
    "# Predict for validation set\n",
    "y_val_pred = lr.predict(x_val)\n",
    "\n",
    "# Metrics\n",
    "precision_lr, recall_lr, fscore_lr, support_lr = precision_recall_fscore_support(\n",
    "    y_val, y_val_pred, average='macro')\n",
    "print(classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kavach/Documents/Dev/Andrew/Assignmet/original.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kavach/Documents/Dev/Andrew/Assignmet/original.ipynb#Y100sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m xgbc \u001b[39m=\u001b[39m XGBClassifier(max_depth\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kavach/Documents/Dev/Andrew/Assignmet/original.ipynb#Y100sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                      n_estimators\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, eval_metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmlogloss\u001b[39m\u001b[39m'\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kavach/Documents/Dev/Andrew/Assignmet/original.ipynb#Y100sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Train the model on the training set\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kavach/Documents/Dev/Andrew/Assignmet/original.ipynb#Y100sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m xgbc\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kavach/Documents/Dev/Andrew/Assignmet/original.ipynb#Y100sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Make predictions on the testing set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kavach/Documents/Dev/Andrew/Assignmet/original.ipynb#Y100sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m y_pred \u001b[39m=\u001b[39m xgbc\u001b[39m.\u001b[39mpredict(x_test)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    531\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 532\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1400\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1379\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(\n\u001b[1;32m   1380\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1381\u001b[0m )\n\u001b[1;32m   1382\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1383\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1384\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1397\u001b[0m     enable_categorical\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menable_categorical,\n\u001b[1;32m   1398\u001b[0m )\n\u001b[0;32m-> 1400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1401\u001b[0m     params,\n\u001b[1;32m   1402\u001b[0m     train_dmatrix,\n\u001b[1;32m   1403\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1404\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1405\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1406\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1407\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1408\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1409\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1410\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1411\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1412\u001b[0m )\n\u001b[1;32m   1414\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1415\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    531\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 532\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:1733\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1732\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1733\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1734\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1735\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1736\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1737\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "xgbc = XGBClassifier(max_depth=10, learning_rate=0.1,\n",
    "                     n_estimators=1000, eval_metric='mlogloss', random_state=100)\n",
    "\n",
    "# Train the model on the training set\n",
    "xgbc.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = xgbc.predict(x_test)\n",
    "\n",
    "# Calculate precision, recall, and f1 score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print precision, recall, and f1 score\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
